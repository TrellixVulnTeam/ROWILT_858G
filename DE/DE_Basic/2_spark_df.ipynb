{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark basic operator & dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe function\n",
    "\n",
    "# df.printSchema() : 스키마 정보를 출력\n",
    "# df.schema : StructType 스키마를 반환\n",
    "# df.columns : 컬럼명 정보를 반환\n",
    "# df.show(n) : 데이터 n 개를 출력\n",
    "# df.first() : 데이터 프레임의 첫 번째 Row 를 반환\n",
    "# df.head(n) : 데이터 프레임의 처음부터 n 개의 Row 를 반환\n",
    "# df.createOrReplaceTempView : 임시 뷰 테이블을 생성\n",
    "# df.union(newdf) : 데이터프레임 간의 유니온 연산을 수행\n",
    "# df.limit(n) : 추출할 로우수 제한\n",
    "# df.repartition(n) : 파티션 재분배, 셔플발생\n",
    "# df.coalesce() : 셔플하지 않고 파티션을 병합 마지막 스테이지의 reduce 수가 줄어드는 효과로 성능저하에 유의해야 함\n",
    "# df.collect() : 모든 데이터 수집, 반환\n",
    "# df.take(n) : 상위 n개 로우 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column function\n",
    "\n",
    "# df.select : 컬럼이나 표현식 사용\n",
    "# df.selectExpr : 문자열 표현식 사용 = df.select(expr())\n",
    "# df.withColumn(컬럼명, 표현식) : 컬럼 추가, 비교, 컬럼명 변경\n",
    "# df.withColumnRenamed(old_name, new_name) : 컬럼명 변경\n",
    "# df.drop() : 컬럼 삭제\n",
    "# df.where : 로우 필터링\n",
    "# df.filter : 로우 필터링\n",
    "# df.sort, df.orderBy : 정렬\n",
    "# df.sortWithinPartitions : 파티션별 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETC\n",
    "\n",
    "# expr(\"someCol - 5\") : 표현식\n",
    "# lit() : 리터럴\n",
    "# cast() : 컬럼 데이터 타입 변경\n",
    "# distinct() : unique row\n",
    "# desc(), asc() : 정렬 순서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data Engineer Basic Day3\") \\\n",
    "    .config(\"spark.dataengineer.intermediate.day3\", \"tutorial-2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cover the spark dataa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Create & use the table from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"data/flight-data/json/2015-summary.json\")\n",
    "df.createOrReplaceTempView(\"2015_summary\")\n",
    "\n",
    "sql_result = spark.sql(\"SELECT * FROM 2015_summary\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Select column (select, selectExpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df.select(upper(col(\"DEST_COUNTRY_NAME\")), \"ORIGIN_COUNTRY_NAME\").show(2)\n",
    "df.selectExpr(\"upper(DEST_COUNTRY_NAME)\", \"ORIGIN_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\"DEST_COUNTRY_NAME as newColmnName\", \"DEST_COUNTRY_NAME\").show(2)\n",
    "\n",
    "df.selectExpr(\"*\", \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Use constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# df.select(expr(\"*\"), lit(1).alias(\"One\")).show(2)\n",
    "df.selectExpr(\"*\", \"1 as One\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"numberOne\", lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df\n",
    "before.printSchema()\n",
    "\n",
    "after = before.withColumn(\"Destination\", expr(\"DEST_COUNTRY_NAME\"))\n",
    "after.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Change column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"Destination\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "df.drop(\"ORIGIN_COUNTRY_NAME\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.caseSensitive', True)\n",
    "caseSensitive = df.drop(\"dest_country_name\")\n",
    "caseSensitive.printSchema()\n",
    "\n",
    "spark.conf.set('spark.sql.caseSensitive', False)\n",
    "caseInsensitive = df.drop(\"dest_country_name\")\n",
    "caseInsensitive.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "df.drop(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Change column data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "\n",
    "int2str = df.withColumn(\"str_count\", col(\"count\").cast(\"string\"))\n",
    "int2str.show(5)\n",
    "int2str.printSchema()\n",
    "\n",
    "str2int = int2str.withColumn(\"int_count\", col(\"str_count\").cast(\"int\"))\n",
    "str2int.show(5)\n",
    "str2int.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Record filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(\"count < 2\").show(2)\n",
    "df.filter(\"count < 2\").show(2)\n",
    "\n",
    "df.where(col(\"count\") < 2).where(col(\"ORIGIN_COUNTRY_NAME\") != \"Croatia\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Distinct value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().count())\n",
    "print(df.select(\"ORIGIN_COUNTRY_NAME\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(\"count\").show(2)\n",
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(2)\n",
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "print(\"# asc_nulls_first, desc_nulls_first, asc_nulls_last, desc_nulls_last 메서드로 null의 정렬 순서를 지정\")\n",
    "df.sort(\"DEST_COUNTRY_NAME\").show(1)\n",
    "df.sort(df[\"DEST_COUNTRY_NAME\"].asc_nulls_first()).show(1)\n",
    "df.sort(df.DEST_COUNTRY_NAME.asc_nulls_first()).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc\n",
    "df.orderBy(df[\"count\"].desc()).show(2)\n",
    "df.orderBy(df.ORIGIN_COUNTRY_NAME.desc(), df.DEST_COUNTRY_NAME.asc()).show(2)\n",
    "df.orderBy(expr(\"ORIGIN_COUNTRY_NAME DESC\"), expr(\"DEST_COUNTRY_NAME ASC\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) Restrict row limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.limit(5).show()\n",
    "df.orderBy(expr(\"count desc\")).limit(6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
